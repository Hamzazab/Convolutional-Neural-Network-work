{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1928891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b277bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Hamza\\Credit Card Fraud Detection with CNN\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fddc40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440df607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4c44b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee9f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b624ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a61d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blance the dataset\n",
    "fraud = df[df['Class']==1]\n",
    "non_fraud = df[df['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555097ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492, 31), (284315, 31))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape , non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1afa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random selection of sample\n",
    "non_fraud_t = non_fraud.sample(n=492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803d9b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0f17e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza\\AppData\\Local\\Temp\\ipykernel_6064\\3589906267.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = fraud.append(non_fraud_t,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#marge the dataset\n",
    "df1 = fraud.append(non_fraud_t,ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb2613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0       406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
      "1       472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
      "2      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
      "3      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
      "4      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "979  135987.0  2.015787 -0.048934 -1.905237  0.347758  0.224952 -0.939994   \n",
      "980   77050.0 -2.258847  1.236628  0.968084 -0.825050 -1.340015 -0.492442   \n",
      "981   72630.0  1.255136  0.277781  0.284105  0.703890 -0.465768 -1.098291   \n",
      "982  141296.0  1.921464  0.275809 -2.744386  0.366749  1.357480  0.286709   \n",
      "983  133886.0  2.251372 -1.566511 -0.719604 -1.662374 -1.422029 -0.152283   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "0   -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
      "1    0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
      "2    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
      "3   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
      "4    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "979  0.003115 -0.069014  0.705439  ...  0.205476  0.610843 -0.055141   \n",
      "980 -0.467012  1.076152  0.443664  ...  0.134377  0.583900 -0.133637   \n",
      "981  0.015794 -0.144254  0.191446  ... -0.299548 -0.915981  0.141808   \n",
      "982 -0.068694  0.275076  0.489892  ...  0.172655  0.707499 -0.037733   \n",
      "983 -1.547799  0.148833 -1.036976  ... -0.116550  0.065774  0.323347   \n",
      "\n",
      "          V24       V25       V26       V27       V28  Amount  Class  \n",
      "0    0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
      "1   -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
      "2   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
      "3   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
      "4   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
      "..        ...       ...       ...       ...       ...     ...    ...  \n",
      "979 -0.592511  0.180263 -0.084216 -0.020176 -0.049398   11.80      0  \n",
      "980  0.626978 -0.022185  0.974920  0.367607  0.248252   40.02      0  \n",
      "981  0.316631  0.180473  0.097901 -0.029973  0.028603    1.98      0  \n",
      "982 -1.883243  0.051595  0.016037  0.056323 -0.022411    1.00      0  \n",
      "983  0.634232 -0.370282 -0.219390  0.011297 -0.053291    6.00      0  \n",
      "\n",
      "[984 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b96ee28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657ddba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select independent variable\n",
    "x = df1.drop(labels=['Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1596be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent variable\n",
    "y = df1['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df71701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((984, 30), (984,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b188ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d60f148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7218e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((787, 30), (787,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "326667a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature sclaing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e938a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5774f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((787, 30), (197, 30))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b216bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(787, 30,1)\n",
    "x_test = x_test.reshape(197, 30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ef279d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((787, 30, 1), (197, 30, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1ebd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d315268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 1st cnn layer\n",
    "model.add(tf.keras.layers.Conv1D(filters=32 , kernel_size=2 , padding='same' , activation='relu',input_shape = (30,1)))\n",
    "\n",
    "#Batch normalization\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Addding Maxpooling\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=2))\n",
    "\n",
    "#Adding dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce1e913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 2nd cnn layer\n",
    "model.add(tf.keras.layers.Conv1D(filters=64 , kernel_size=2 , padding='same' , activation='relu'))\n",
    "\n",
    "#Batch normalization\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Addding Maxpooling\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=2))\n",
    "\n",
    "#Adding dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87a96fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Flatten layer\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c7c65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding FCL \n",
    "model.add(tf.keras.layers.Dense(units=64,activation='relu'))\n",
    "\n",
    "#Adding dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "837cee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25d89864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 30, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 15, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 32)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15, 64)            4160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 7, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 448)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                28736     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,441\n",
      "Trainable params: 33,249\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5dfb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#compile the model\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "model.compile(optimizer=opt , loss='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6456b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/134\n",
      "25/25 [==============================] - 2s 20ms/step - loss: 1.5357 - accuracy: 0.3914 - val_loss: 0.7387 - val_accuracy: 0.3655\n",
      "Epoch 2/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.4102 - accuracy: 0.4168 - val_loss: 0.7310 - val_accuracy: 0.4010\n",
      "Epoch 3/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.2768 - accuracy: 0.4333 - val_loss: 0.7234 - val_accuracy: 0.4569\n",
      "Epoch 4/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.2649 - accuracy: 0.4269 - val_loss: 0.7173 - val_accuracy: 0.5127\n",
      "Epoch 5/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.1413 - accuracy: 0.4663 - val_loss: 0.7117 - val_accuracy: 0.5431\n",
      "Epoch 6/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1.1431 - accuracy: 0.4816 - val_loss: 0.7069 - val_accuracy: 0.5635\n",
      "Epoch 7/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0570 - accuracy: 0.4981 - val_loss: 0.7011 - val_accuracy: 0.5736\n",
      "Epoch 8/134\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.0126 - accuracy: 0.5184 - val_loss: 0.6933 - val_accuracy: 0.5787\n",
      "Epoch 9/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9856 - accuracy: 0.5032 - val_loss: 0.6831 - val_accuracy: 0.5990\n",
      "Epoch 10/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.9823 - accuracy: 0.5489 - val_loss: 0.6695 - val_accuracy: 0.6142\n",
      "Epoch 11/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9580 - accuracy: 0.5375 - val_loss: 0.6526 - val_accuracy: 0.6345\n",
      "Epoch 12/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8895 - accuracy: 0.5667 - val_loss: 0.6340 - val_accuracy: 0.6497\n",
      "Epoch 13/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8339 - accuracy: 0.5705 - val_loss: 0.6131 - val_accuracy: 0.6954\n",
      "Epoch 14/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7929 - accuracy: 0.5934 - val_loss: 0.5917 - val_accuracy: 0.7462\n",
      "Epoch 15/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7854 - accuracy: 0.6125 - val_loss: 0.5690 - val_accuracy: 0.7513\n",
      "Epoch 16/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7550 - accuracy: 0.6188 - val_loss: 0.5465 - val_accuracy: 0.8020\n",
      "Epoch 17/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7346 - accuracy: 0.6239 - val_loss: 0.5258 - val_accuracy: 0.8071\n",
      "Epoch 18/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.6569 - val_loss: 0.5049 - val_accuracy: 0.8274\n",
      "Epoch 19/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.6480 - val_loss: 0.4862 - val_accuracy: 0.8376\n",
      "Epoch 20/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6670 - accuracy: 0.6633 - val_loss: 0.4684 - val_accuracy: 0.8426\n",
      "Epoch 21/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6675 - accuracy: 0.6709 - val_loss: 0.4528 - val_accuracy: 0.8376\n",
      "Epoch 22/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.7027 - val_loss: 0.4390 - val_accuracy: 0.8528\n",
      "Epoch 23/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.6874 - val_loss: 0.4258 - val_accuracy: 0.8579\n",
      "Epoch 24/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5890 - accuracy: 0.7039 - val_loss: 0.4139 - val_accuracy: 0.8629\n",
      "Epoch 25/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5724 - accuracy: 0.7128 - val_loss: 0.4039 - val_accuracy: 0.8629\n",
      "Epoch 26/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5841 - accuracy: 0.7065 - val_loss: 0.3947 - val_accuracy: 0.8731\n",
      "Epoch 27/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5542 - accuracy: 0.7306 - val_loss: 0.3859 - val_accuracy: 0.8782\n",
      "Epoch 28/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5635 - accuracy: 0.7294 - val_loss: 0.3775 - val_accuracy: 0.8731\n",
      "Epoch 29/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5403 - accuracy: 0.7459 - val_loss: 0.3701 - val_accuracy: 0.8731\n",
      "Epoch 30/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5359 - accuracy: 0.7332 - val_loss: 0.3635 - val_accuracy: 0.8731\n",
      "Epoch 31/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5452 - accuracy: 0.7497 - val_loss: 0.3572 - val_accuracy: 0.8731\n",
      "Epoch 32/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.7217 - val_loss: 0.3505 - val_accuracy: 0.8731\n",
      "Epoch 33/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.7700 - val_loss: 0.3447 - val_accuracy: 0.8680\n",
      "Epoch 34/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.7700 - val_loss: 0.3390 - val_accuracy: 0.8680\n",
      "Epoch 35/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4949 - accuracy: 0.7662 - val_loss: 0.3336 - val_accuracy: 0.8680\n",
      "Epoch 36/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5326 - accuracy: 0.7446 - val_loss: 0.3286 - val_accuracy: 0.8731\n",
      "Epoch 37/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4884 - accuracy: 0.7726 - val_loss: 0.3238 - val_accuracy: 0.8731\n",
      "Epoch 38/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.8005 - val_loss: 0.3201 - val_accuracy: 0.8782\n",
      "Epoch 39/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5073 - accuracy: 0.7789 - val_loss: 0.3163 - val_accuracy: 0.8832\n",
      "Epoch 40/134\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.7929 - val_loss: 0.3121 - val_accuracy: 0.8883\n",
      "Epoch 41/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7827 - val_loss: 0.3081 - val_accuracy: 0.8883\n",
      "Epoch 42/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.7929 - val_loss: 0.3045 - val_accuracy: 0.8934\n",
      "Epoch 43/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4696 - accuracy: 0.7814 - val_loss: 0.3012 - val_accuracy: 0.8985\n",
      "Epoch 44/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7916 - val_loss: 0.2976 - val_accuracy: 0.8985\n",
      "Epoch 45/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4452 - accuracy: 0.7980 - val_loss: 0.2943 - val_accuracy: 0.8985\n",
      "Epoch 46/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8234 - val_loss: 0.2912 - val_accuracy: 0.8985\n",
      "Epoch 47/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4670 - accuracy: 0.7980 - val_loss: 0.2884 - val_accuracy: 0.8985\n",
      "Epoch 48/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.8081 - val_loss: 0.2860 - val_accuracy: 0.8985\n",
      "Epoch 49/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8208 - val_loss: 0.2832 - val_accuracy: 0.8985\n",
      "Epoch 50/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8259 - val_loss: 0.2803 - val_accuracy: 0.9036\n",
      "Epoch 51/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8234 - val_loss: 0.2780 - val_accuracy: 0.9036\n",
      "Epoch 52/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4255 - accuracy: 0.8094 - val_loss: 0.2757 - val_accuracy: 0.8985\n",
      "Epoch 53/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8196 - val_loss: 0.2735 - val_accuracy: 0.8985\n",
      "Epoch 54/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.8170 - val_loss: 0.2720 - val_accuracy: 0.8985\n",
      "Epoch 55/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3834 - accuracy: 0.8272 - val_loss: 0.2695 - val_accuracy: 0.9036\n",
      "Epoch 56/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3960 - accuracy: 0.8450 - val_loss: 0.2673 - val_accuracy: 0.9036\n",
      "Epoch 57/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3729 - accuracy: 0.8450 - val_loss: 0.2652 - val_accuracy: 0.9036\n",
      "Epoch 58/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8285 - val_loss: 0.2630 - val_accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8348 - val_loss: 0.2610 - val_accuracy: 0.9036\n",
      "Epoch 60/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8386 - val_loss: 0.2594 - val_accuracy: 0.9036\n",
      "Epoch 61/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4044 - accuracy: 0.8335 - val_loss: 0.2571 - val_accuracy: 0.9036\n",
      "Epoch 62/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3887 - accuracy: 0.8399 - val_loss: 0.2554 - val_accuracy: 0.9036\n",
      "Epoch 63/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8463 - val_loss: 0.2535 - val_accuracy: 0.9036\n",
      "Epoch 64/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3485 - accuracy: 0.8653 - val_loss: 0.2516 - val_accuracy: 0.9036\n",
      "Epoch 65/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3834 - accuracy: 0.8424 - val_loss: 0.2500 - val_accuracy: 0.9036\n",
      "Epoch 66/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3770 - accuracy: 0.8488 - val_loss: 0.2488 - val_accuracy: 0.9036\n",
      "Epoch 67/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.8501 - val_loss: 0.2473 - val_accuracy: 0.9036\n",
      "Epoch 68/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8615 - val_loss: 0.2458 - val_accuracy: 0.9086\n",
      "Epoch 69/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3615 - accuracy: 0.8450 - val_loss: 0.2442 - val_accuracy: 0.9086\n",
      "Epoch 70/134\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3602 - accuracy: 0.8539 - val_loss: 0.2429 - val_accuracy: 0.9086\n",
      "Epoch 71/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3513 - accuracy: 0.8590 - val_loss: 0.2417 - val_accuracy: 0.9086\n",
      "Epoch 72/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.8539 - val_loss: 0.2402 - val_accuracy: 0.9086\n",
      "Epoch 73/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.8640 - val_loss: 0.2387 - val_accuracy: 0.9086\n",
      "Epoch 74/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3621 - accuracy: 0.8564 - val_loss: 0.2375 - val_accuracy: 0.9086\n",
      "Epoch 75/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.8640 - val_loss: 0.2361 - val_accuracy: 0.9086\n",
      "Epoch 76/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3393 - accuracy: 0.8628 - val_loss: 0.2351 - val_accuracy: 0.9086\n",
      "Epoch 77/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3347 - accuracy: 0.8666 - val_loss: 0.2339 - val_accuracy: 0.9086\n",
      "Epoch 78/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8551 - val_loss: 0.2324 - val_accuracy: 0.9137\n",
      "Epoch 79/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8666 - val_loss: 0.2310 - val_accuracy: 0.9137\n",
      "Epoch 80/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3188 - accuracy: 0.8666 - val_loss: 0.2296 - val_accuracy: 0.9137\n",
      "Epoch 81/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.8653 - val_loss: 0.2286 - val_accuracy: 0.9188\n",
      "Epoch 82/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3422 - accuracy: 0.8602 - val_loss: 0.2275 - val_accuracy: 0.9188\n",
      "Epoch 83/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3412 - accuracy: 0.8577 - val_loss: 0.2264 - val_accuracy: 0.9239\n",
      "Epoch 84/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8767 - val_loss: 0.2253 - val_accuracy: 0.9239\n",
      "Epoch 85/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3409 - accuracy: 0.8577 - val_loss: 0.2244 - val_accuracy: 0.9239\n",
      "Epoch 86/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8717 - val_loss: 0.2233 - val_accuracy: 0.9239\n",
      "Epoch 87/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3468 - accuracy: 0.8653 - val_loss: 0.2222 - val_accuracy: 0.9289\n",
      "Epoch 88/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8666 - val_loss: 0.2214 - val_accuracy: 0.9289\n",
      "Epoch 89/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.8704 - val_loss: 0.2204 - val_accuracy: 0.9289\n",
      "Epoch 90/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3396 - accuracy: 0.8704 - val_loss: 0.2195 - val_accuracy: 0.9289\n",
      "Epoch 91/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3416 - accuracy: 0.8615 - val_loss: 0.2186 - val_accuracy: 0.9289\n",
      "Epoch 92/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.8640 - val_loss: 0.2179 - val_accuracy: 0.9289\n",
      "Epoch 93/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8615 - val_loss: 0.2171 - val_accuracy: 0.9289\n",
      "Epoch 94/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3291 - accuracy: 0.8679 - val_loss: 0.2160 - val_accuracy: 0.9289\n",
      "Epoch 95/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8869 - val_loss: 0.2151 - val_accuracy: 0.9289\n",
      "Epoch 96/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8742 - val_loss: 0.2143 - val_accuracy: 0.9289\n",
      "Epoch 97/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8691 - val_loss: 0.2135 - val_accuracy: 0.9289\n",
      "Epoch 98/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3284 - accuracy: 0.8780 - val_loss: 0.2125 - val_accuracy: 0.9289\n",
      "Epoch 99/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.8806 - val_loss: 0.2118 - val_accuracy: 0.9289\n",
      "Epoch 100/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.8742 - val_loss: 0.2111 - val_accuracy: 0.9289\n",
      "Epoch 101/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.8767 - val_loss: 0.2103 - val_accuracy: 0.9289\n",
      "Epoch 102/134\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2895 - accuracy: 0.8818 - val_loss: 0.2096 - val_accuracy: 0.9289\n",
      "Epoch 103/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3057 - accuracy: 0.8742 - val_loss: 0.2090 - val_accuracy: 0.9289\n",
      "Epoch 104/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3121 - accuracy: 0.8869 - val_loss: 0.2087 - val_accuracy: 0.9289\n",
      "Epoch 105/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3424 - accuracy: 0.8831 - val_loss: 0.2080 - val_accuracy: 0.9340\n",
      "Epoch 106/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3213 - accuracy: 0.8831 - val_loss: 0.2075 - val_accuracy: 0.9340\n",
      "Epoch 107/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2860 - accuracy: 0.8945 - val_loss: 0.2071 - val_accuracy: 0.9289\n",
      "Epoch 108/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2973 - accuracy: 0.8971 - val_loss: 0.2065 - val_accuracy: 0.9289\n",
      "Epoch 109/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3099 - accuracy: 0.8704 - val_loss: 0.2058 - val_accuracy: 0.9340\n",
      "Epoch 110/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.8717 - val_loss: 0.2050 - val_accuracy: 0.9340\n",
      "Epoch 111/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3074 - accuracy: 0.8920 - val_loss: 0.2038 - val_accuracy: 0.9340\n",
      "Epoch 112/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2829 - accuracy: 0.8882 - val_loss: 0.2031 - val_accuracy: 0.9340\n",
      "Epoch 113/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.8856 - val_loss: 0.2024 - val_accuracy: 0.9340\n",
      "Epoch 114/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2930 - accuracy: 0.8920 - val_loss: 0.2020 - val_accuracy: 0.9340\n",
      "Epoch 115/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2719 - accuracy: 0.9085 - val_loss: 0.2013 - val_accuracy: 0.9340\n",
      "Epoch 116/134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3166 - accuracy: 0.8793 - val_loss: 0.2006 - val_accuracy: 0.9340\n",
      "Epoch 117/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.8971 - val_loss: 0.2001 - val_accuracy: 0.9340\n",
      "Epoch 118/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2990 - accuracy: 0.8920 - val_loss: 0.1991 - val_accuracy: 0.9340\n",
      "Epoch 119/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2663 - accuracy: 0.8996 - val_loss: 0.1984 - val_accuracy: 0.9340\n",
      "Epoch 120/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2884 - accuracy: 0.8856 - val_loss: 0.1982 - val_accuracy: 0.9340\n",
      "Epoch 121/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2812 - accuracy: 0.8933 - val_loss: 0.1977 - val_accuracy: 0.9340\n",
      "Epoch 122/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2836 - accuracy: 0.8882 - val_loss: 0.1970 - val_accuracy: 0.9340\n",
      "Epoch 123/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2868 - accuracy: 0.8920 - val_loss: 0.1963 - val_accuracy: 0.9340\n",
      "Epoch 124/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8818 - val_loss: 0.1957 - val_accuracy: 0.9340\n",
      "Epoch 125/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8933 - val_loss: 0.1954 - val_accuracy: 0.9340\n",
      "Epoch 126/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2780 - accuracy: 0.9009 - val_loss: 0.1950 - val_accuracy: 0.9340\n",
      "Epoch 127/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2771 - accuracy: 0.8958 - val_loss: 0.1948 - val_accuracy: 0.9340\n",
      "Epoch 128/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2548 - accuracy: 0.9111 - val_loss: 0.1942 - val_accuracy: 0.9340\n",
      "Epoch 129/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2773 - accuracy: 0.9111 - val_loss: 0.1938 - val_accuracy: 0.9340\n",
      "Epoch 130/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2534 - accuracy: 0.9060 - val_loss: 0.1932 - val_accuracy: 0.9340\n",
      "Epoch 131/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2690 - accuracy: 0.9034 - val_loss: 0.1927 - val_accuracy: 0.9340\n",
      "Epoch 132/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2819 - accuracy: 0.8971 - val_loss: 0.1920 - val_accuracy: 0.9340\n",
      "Epoch 133/134\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2654 - accuracy: 0.9022 - val_loss: 0.1913 - val_accuracy: 0.9340\n",
      "Epoch 134/134\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2916 - accuracy: 0.8882 - val_loss: 0.1907 - val_accuracy: 0.9340\n"
     ]
    }
   ],
   "source": [
    "#traing the model\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=134,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a079ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7584048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99984354]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred[12]) , print(y_test[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00897060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   0]\n",
      " [ 13  78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Convert continuous predictions to binary labels based on a threshold\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
